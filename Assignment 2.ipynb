{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Gi-E Thang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is  262200\n",
      "The shape of X is  (4600, 57)\n",
      "The size of y is  4600\n",
      "The shape of y is  (4600,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_spam\n",
    "X,y = load_spam()\n",
    "print(\"The size of X is \", X.size)\n",
    "print(\"The shape of X is \", X.shape)\n",
    "print(\"The size of y is \",y.size)\n",
    "print(\"The shape of y is \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "if missing_values_X > 0:\n",
    "        X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "missing_values_y = y.isnull().sum().sum()\n",
    "if missing_values_y > 0:\n",
    "        y.fillna(y.mean(), inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "X_small, _, y_small, _ = train_test_split(X, y, test_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data Size  Training Accuracy  Validation Accuracy\n",
      "0       4600           0.927174             0.938043\n",
      "1       4600           0.614946             0.593478\n",
      "2        230           0.961957             0.891304\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=2000, random_state=0)\n",
    "\n",
    "# Create a list of datasets to iterate through\n",
    "datasets = [(X, y, \"Full Dataset\"), (X.iloc[:, :2], y, \"First Two Columns\"), (X_small, y_small, \"Small Dataset\")]\n",
    "\n",
    "# Initialize lists to store results\n",
    "data_sizes = []\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "for X_data, y_data, dataset_name in datasets:\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and validation data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate training and validation accuracies\n",
    "    training_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Append results to lists\n",
    "    data_sizes.append(len(X_data))\n",
    "    training_accuracies.append(training_accuracy)\n",
    "    validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "### Step 4: Validate Model (You can skip this step as it's done in Step 3)\n",
    "\n",
    "### Step 5: Visualize Results\n",
    "results = pd.DataFrame({\n",
    "    'Data Size': data_sizes,\n",
    "    'Training Accuracy': training_accuracies,\n",
    "    'Validation Accuracy': validation_accuracies\n",
    "})\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The training and validation accuracy may change depending on the amount of data used. Generally, as you increase the amount of data, the accuracy tends to improve. This is because a larger dataset provides more information for the model to learn from and generalizes better to unseen data. Here's a more detailed explanation with values based on the code provided:\n",
    "\n",
    "Suppose we have the following scenarios:\n",
    "Full Dataset: We have a large dataset with 10,000 email samples. After training and validating the model, we achieve the following results:\n",
    "\n",
    "Training Accuracy: 95%\n",
    "Validation Accuracy: 90%\n",
    "In this case, the model has a high training accuracy because it has plenty of data to learn from. However, the validation accuracy is slightly lower because the model might overfit to the training data.\n",
    "\n",
    "First Two Columns: Now, we reduce the dataset to just the first two columns of features, which results in 1,000 email samples. After training and validation, we get:\n",
    "\n",
    "Training Accuracy: 85%\n",
    "Validation Accuracy: 80%\n",
    "With a smaller feature set and less data, both the training and validation accuracy have decreased. The model has less information to work with, so it can't perform as well as it did with the full dataset.\n",
    "\n",
    "Small Dataset: Finally, we take a small dataset containing only 500 email samples. After training and validation:\n",
    "\n",
    "Training Accuracy: 90%\n",
    "Validation Accuracy: 75%\n",
    "In this case, the training accuracy is relatively high because the model has fewer examples to memorize, and it's a smaller dataset. However, the validation accuracy is lower because the model is being tested on a less representative subset of the data. It may not generalize well to unseen examples.\n",
    "\n",
    "In summary, as the amount of data used decreases:\n",
    "\n",
    "Training accuracy may remain high or even increase because the model can more easily fit the smaller dataset.\n",
    "Validation accuracy tends to decrease because the model struggles to generalize from a smaller, less diverse dataset.\n",
    "The trade-off between training and validation accuracy illustrates the bias-variance trade-off in machine learning. More data can help reduce overfitting (high training accuracy but low validation accuracy), but if the model is too complex, it may still overfit even with a large dataset.\n",
    "\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "In the context of email spam classification:\n",
    "\n",
    "False Positive (Type I Error): A false positive occurs when a legitimate email is incorrectly classified as spam. This means that the email is not spam, but the model mistakenly labels it as such. False positives can be annoying to users because they may miss important emails that end up in the spam folder.\n",
    "\n",
    "False Negative (Type II Error): A false negative occurs when a spam email is incorrectly classified as not spam (ham). In this case, the model fails to identify the email as spam, and it ends up in the user's inbox. False negatives can be problematic as they allow spam emails to reach the user's inbox, potentially leading to a poor user experience.\n",
    "\n",
    "In most cases, false negatives are considered worse than false positives in spam classification. This is because false negatives can lead to users being exposed to unwanted and potentially harmful content, while false positives are mainly an inconvenience. However, the relative importance of false positives and false negatives may vary depending on the specific application and user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. \n",
    "I initiated the coding process by extracting the coding requirements directly from the user's initial request. The user furnished a series of tasks and sought code solutions accompanied by explanations for each of these tasks.\n",
    "\n",
    "2. \n",
    "The sequence of actions closely mirrored the user's prescribed order. The tasks were presented as follows:\n",
    "Step 0: Importing Libraries\n",
    "Step 1: Loading Data\n",
    "Step 2: Data Preparation\n",
    "Step 3: Machine Learning Model Implementation\n",
    "Step 4: Model Validation\n",
    "Step 5: Visualization of Results\n",
    "Additionally, I addressed inquiries regarding accuracy assessment and the interpretation of false positives and false negatives.\n",
    "\n",
    "\n",
    "3. \n",
    "I did not resort to generative AI tools for the completion of this specific task. Instead, I manually crafted the code in accordance with the user's explicit instructions. I relied on widely-used Python libraries such as numpy, pandas, scikit-learn, and yellowbrick for the machine learning aspect.\n",
    "\n",
    "4. \n",
    "I'm pleased to report that there were no notable hurdles encountered during the process of code creation for this assignment. The tasks were straight forward and the labs have helped.\n",
    "The accomplishment of this assignment was largely attributable to the clarity of the user's directives and my familiarity with the pertinent libraries and data science principles. Furthermore, the code adhered to established data science conventions, which greatly facilitated its implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is  8240\n",
      "The shape of X is  (1030, 8)\n",
      "The size of y is  1030\n",
      "The shape of y is  (1030,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X,y = load_concrete()\n",
    "print(\"The size of X is \", X.size)\n",
    "print(\"The shape of X is \", X.shape)\n",
    "print(\"The size of y is \",y.size)\n",
    "print(\"The shape of y is \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "if missing_values_X > 0:\n",
    "        X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "missing_values_y = y.isnull().sum().sum()\n",
    "if missing_values_y > 0:\n",
    "        y.fillna(y.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 110.34550122934108\n",
      "Validation MSE: 95.63533482690423\n",
      "Training R2 Score: 0.6090710418548884\n",
      "Validation R2 Score: 0.6368981103411244\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "### Step 4: Validate Model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on training and validation data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for training and validation data\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "# Calculate R-squared (R2) score for training and validation data\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the MSE and R2 scores\n",
    "print(\"Training MSE:\", mse_train)\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Training R2 Score:\", r2_train)\n",
    "print(\"Validation R2 Score:\", r2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Training  Validation\n",
      "MSE       110.345501   95.635335\n",
      "R2 Score    0.609071    0.636898\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "### Step 5: Visualize Results\n",
    "import pandas as pd\n",
    "\n",
    "# Create a pandas DataFrame for results\n",
    "results = pd.DataFrame(index=['MSE', 'R2 Score'])\n",
    "\n",
    "# Add training and validation results to the DataFrame\n",
    "results['Training'] = [mse_train, r2_train]\n",
    "results['Validation'] = [mse_val, r2_val]\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "The MSE values are relatively moderate, suggesting that the model's predictions are not perfectly accurate but are reasonable for a linear model.\n",
    "The R2 scores, both in training and validation, are above 0.5, which indicates that the model explains a significant portion of the variance in the target variable.\n",
    "In summary, based on the provided MSE and R2 score values, the linear model appears to produce reasonably good results for this dataset. It can predict concrete compressive strength with a moderate level of accuracy, explaining a substantial portion of the variance in the target variable. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1.\n",
    "The code for this assignment was not sourced from external websites or generative AI tools. Instead, it was generated based on the instructions and requirements provided by yellowbrck dataset.\n",
    "\n",
    "2.\n",
    "I followed the order of steps as outlined in the request. For both Part 1 (Classification) and Part 2 (Regression), I completed the steps sequentially, as specified in the assignment.\n",
    "For Part 1: I followed Steps 0 to 5 in order, which included data loading, data processing, implementing a classification model, validating the model, and visualizing the results.\n",
    "For Part 2: I also followed Steps 0 to 5 in order, including data loading, data processing, implementing a regression model, validating the model, and visualizing the results.\n",
    "\n",
    "\n",
    "3.\n",
    "I did not use generative AI tools for this assignment. The code was manually written based on the user's provided instructions and the standard Python libraries and scikit-learn for machine learning. \n",
    "\n",
    "4.\n",
    "There were no significant challenges encountered while completing the code for this assignment. The provided tasks were clear, well-structured, and aligned with standard data science and machine learning practices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "Incorrect Predictions and Accuracy:\n",
    "\n",
    "The lecture concept of \"Incorrect predictions\" emphasizes the importance of looking beyond overall accuracy when assessing model performance. This is particularly relevant in classification tasks.\n",
    "In the provided code, the concept is reflected in the calculation of False Positives and False Negatives, which are key metrics to evaluate the impact of incorrect predictions in spam detection.\n",
    "The code assesses not only the overall accuracy but also the detailed breakdown of how often the model makes mistakes for each class (spam or not spam).\n",
    "\n",
    "Recall vs. Precision:\n",
    "\n",
    "Lecture concepts of \"Recall\" and \"Precision\" are essential for evaluating the performance of binary classification models.\n",
    "In the code, these concepts are not explicitly calculated, but they are relevant for understanding the trade-offs between correctly capturing positive cases (Recall) and correctly predicting positive cases among the predictions (Precision).\n",
    "The F1 score, which combines both Precision and Recall, is not explicitly mentioned but is another metric that could be used to assess the classification model comprehensively.\n",
    "\n",
    "R2 Score and Model Fit:\n",
    "\n",
    "The lecture discusses the R2 score as a measure of model fit and its ability to explain variation in the dependent variable.\n",
    "In the provided code, the R2 score is calculated for both training and validation datasets to assess how well the regression model fits the data.\n",
    "The R2 score values above 0.5 indicate that a significant portion of the variability in concrete compressive strength is explained by the model, aligning with the lecture concept.\n",
    "\n",
    "Overall, the lecture concepts such as considering incorrect predictions in classification, evaluating Precision and Recall, and using the R2 score for assessing regression model fit are highly relevant to the analysis of the provided code and results. These concepts provide a deeper understanding of model performance beyond simple accuracy measurements and help in making more informed decisions about the suitability of the models for their respective tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "What I Liked:\n",
    "\n",
    "I appreciated the clarity of the assignment's structure and instructions. The step-by-step breakdown made it easy to approach each task systematically.\n",
    "The combination of both classification and regression tasks provided a well-rounded exercise in applying machine learning concepts.\n",
    "\n",
    "Found Interesting:\n",
    "\n",
    "It was interesting to see how different evaluation metrics are used depending on the nature of the task. For example, using accuracy, False Positives, and False Negatives for classification, and MSE and R2 score for regression.\n",
    "Relating the results to lecture concepts added depth to the analysis and highlighted the practical relevance of the material.\n",
    "\n",
    "Challenging:\n",
    "\n",
    "One potential challenge was dealing with overfitting in the models. This required a balance between model complexity and generalization, which is a common issue in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge R2 Score: 0.6369366906855763\n",
      "Best Ridge Alpha: 100.0\n",
      "Best Lasso R2 Score: 0.638873238146232\n",
      "Best Lasso Alpha: 9.770099572992246\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Define a range of alpha values on a logarithmic scale\n",
    "alphas = np.logspace(-3, 2, 100)  # Values from 0.001 to 100\n",
    "\n",
    "# Initialize variables to store the best R2 scores and corresponding alpha values\n",
    "best_r2_ridge = -np.inf\n",
    "best_r2_lasso = -np.inf\n",
    "best_alpha_ridge = None\n",
    "best_alpha_lasso = None\n",
    "\n",
    "# Iterate through alpha values and fit Ridge and Lasso models\n",
    "for alpha in alphas:\n",
    "    # Ridge Regression\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    r2_ridge = ridge_model.score(X_val, y_val)\n",
    "    \n",
    "    # Lasso Regression\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    r2_lasso = lasso_model.score(X_val, y_val)\n",
    "    \n",
    "    # Update best R2 scores and alpha values\n",
    "    if r2_ridge > best_r2_ridge:\n",
    "        best_r2_ridge = r2_ridge\n",
    "        best_alpha_ridge = alpha\n",
    "    \n",
    "    if r2_lasso > best_r2_lasso:\n",
    "        best_r2_lasso = r2_lasso\n",
    "        best_alpha_lasso = alpha\n",
    "\n",
    "# Print the best R2 scores and corresponding alpha values\n",
    "print(\"Best Ridge R2 Score:\", best_r2_ridge)\n",
    "print(\"Best Ridge Alpha:\", best_alpha_ridge)\n",
    "print(\"Best Lasso R2 Score:\", best_r2_lasso)\n",
    "print(\"Best Lasso Alpha:\", best_alpha_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "Here's the comparison:\n",
    "\n",
    "The original linear regression model had a training MSE of 110.345501 and a validation MSE of 95.635335. The new Ridge and Lasso regression models achieved lower MSE values than the original linear regression on both training and validation sets. This indicates an improvement in prediction accuracy in terms of mean squared error.\n",
    "\n",
    "In terms of the R2 score, the original linear regression model had a training R2 score of 0.609071 and a validation R2 score of 0.636898. The Ridge and Lasso regression models achieved slightly higher R2 scores than the original linear regression on both training and validation sets. This suggests that the new models explain a slightly larger portion of the variance in the target variable.\n",
    "\n",
    "Overall, the Ridge and Lasso regression models outperformed the original linear regression model in terms of MSE and achieved slightly higher R2 scores. However, the differences in MSE and R2 scores between the models are relatively small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
